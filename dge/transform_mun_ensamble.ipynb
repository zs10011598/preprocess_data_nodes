{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import psycopg2\n",
    "import progressbar\n",
    "from datetime import datetime\n",
    "\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Las bases de datos deben estar creadas\n",
    "\n",
    "dbmesh = 'epi_puma_meshes'\n",
    "dbname = 'epi_puma_covid19_1'\n",
    "dbuser = 'postgres'\n",
    "dbpass = 'postgres'\n",
    "dbport = 5432\n",
    "dbhost = '127.0.0.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'covid-19_processed.csv' \n",
    "total_ocurrences = 7380367\n",
    "times = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Poner None en la columna donde el dataset no tenga malla\n",
    "map_grid = {'state': 'state', 'mun':'mun', 'ageb': None}\n",
    "\n",
    "columns_types = {}\n",
    "columns_types['state'] = str\n",
    "columns_types['mun'] = str\n",
    "\n",
    "covar_attributes = ['CLASIFICACION_FINAL']\n",
    "listed_attributes = ''\n",
    "date_column = 'FECHA_SINTOMAS'.lower()\n",
    "\n",
    "for attr in covar_attributes:\n",
    "    listed_attributes += attr + ','\n",
    "\n",
    "listed_attributes = listed_attributes[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conf Meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "meshes = ['state', 'mun', 'ageb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 201028COVID19MEXICO.csv       datos_abiertos_covid19.zip\r\n",
      " 210504COVID19MEXICO.csv      'diccionario_datos_covid19(1)'\r\n",
      " 210623COVID19MEXICO.csv      'diccionario_datos_covid19(1).zip'\r\n",
      " covid-19_processed.csv        epi_puma_id_cell.ipynb\r\n",
      " covid-19_processed.tar.gz     procesamiento_dataset.ipynb\r\n",
      " datos_abiertos_20210505.zip   procesamiento_dataset.py\r\n",
      " datos_abiertos_20210624.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0  size:  369017  from:  0  to:  369017\n",
      "batch:  1  size:  369018  from:  369018  to:  738035\n",
      "batch:  2  size:  369019  from:  738036  to:  1107054\n",
      "batch:  3  size:  369018  from:  1107055  to:  1476072\n",
      "batch:  4  size:  369018  from:  1476073  to:  1845090\n",
      "batch:  5  size:  369019  from:  1845091  to:  2214109\n",
      "batch:  6  size:  369018  from:  2214110  to:  2583127\n",
      "batch:  7  size:  369018  from:  2583128  to:  2952145\n",
      "batch:  8  size:  369019  from:  2952146  to:  3321164\n",
      "batch:  9  size:  369018  from:  3321165  to:  3690182\n",
      "batch:  10  size:  369018  from:  3690183  to:  4059200\n",
      "batch:  11  size:  369019  from:  4059201  to:  4428219\n",
      "batch:  12  size:  369018  from:  4428220  to:  4797237\n",
      "batch:  13  size:  369018  from:  4797238  to:  5166255\n",
      "batch:  14  size:  369019  from:  5166256  to:  5535274\n",
      "batch:  15  size:  369018  from:  5535275  to:  5904292\n",
      "batch:  16  size:  369018  from:  5904293  to:  6273310\n",
      "batch:  17  size:  369019  from:  6273311  to:  6642329\n",
      "batch:  18  size:  369018  from:  6642330  to:  7011347\n",
      "batch:  19  size:  369018  from:  7011348  to:  7380365\n"
     ]
    }
   ],
   "source": [
    "conn_string = 'postgresql://{dbuser}:{dbpass}@{dbhost}:{dbport}/{dbname}'.format(dbuser=dbuser, \n",
    "                                                                                 dbpass=dbpass,\n",
    "                                                                                 dbhost=dbhost,\n",
    "                                                                                 dbport=dbport,\n",
    "                                                                                 dbname=dbname)\n",
    "for i in range(times):\n",
    "    offset = int(i*total_ocurrences/times)\n",
    "    until = int((i+1)*total_ocurrences/times) - int((i+1)/times)\n",
    "    \n",
    "    df = pd.read_csv(filename, dtype=columns_types, skiprows=lambda x: not (x in range(offset, until) or x == 0))\n",
    "    \n",
    "    l = df.columns.tolist()\n",
    "    d = {x:x.lower() for x in l}\n",
    "    df = df.rename(columns=d)\n",
    "    \n",
    "    for mesh in map_grid.keys():\n",
    "        if map_grid[mesh] != None:\n",
    "            df = df.rename(columns={map_grid[mesh]: 'gridid_' + mesh})\n",
    "        else:\n",
    "            df['gridid_' + mesh] = pd.Series(df.shape[0]*[''])\n",
    "            \n",
    "    df['date_occurrence'] = pd.to_datetime(df[date_column]) \n",
    "    \n",
    "    print('batch: ', i, ' size: ', df.shape[0], ' from: ', offset, ' to: ', until-1)\n",
    "    \n",
    "    engine = create_engine(conn_string)\n",
    "    df.to_sql('occurrence', engine, if_exists='append', index=False, chunksize=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    for mesh in meshes:\n",
    "        sql = \"CREATE INDEX idx_occurrence_gridid_{grid} ON occurrence(gridid_{grid})\".format(grid=mesh)\n",
    "        conn.execute(sql)\n",
    "    \n",
    "    sql = \"CREATE INDEX idx_occurrence_date_occurrence ON occurrence(date_occurrence)\".format(grid=mesh)\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7  covars\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT DISTINCT {0} FROM occurrence\".format(listed_attributes))\n",
    "results = cur.fetchall()\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(len(results), ' covars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clasificacion_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NEGATIVO A SARS-COV-2 POR LABORATORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASO DE SARS-COV-2  CONFIRMADO POR LABORATORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASO DE COVID-19 CONFIRMADO POR ASOCIACIÓN CLÍ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO REALIZADO POR LABORATORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CASO DE COVID-19 CONFIRMADO POR COMITÉ DE  DIC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INVÁLIDO POR LABORATORIO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CASO SOSPECHOSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 clasificacion_final\n",
       "0              NEGATIVO A SARS-COV-2 POR LABORATORIO\n",
       "1     CASO DE SARS-COV-2  CONFIRMADO POR LABORATORIO\n",
       "2  CASO DE COVID-19 CONFIRMADO POR ASOCIACIÓN CLÍ...\n",
       "3                       NO REALIZADO POR LABORATORIO\n",
       "4  CASO DE COVID-19 CONFIRMADO POR COMITÉ DE  DIC...\n",
       "5                           INVÁLIDO POR LABORATORIO\n",
       "6                                    CASO SOSPECHOSO"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_attributes = len(covar_attributes)\n",
    "records = {}\n",
    "\n",
    "index = 0\n",
    "for r in results:\n",
    "    aux = {}\n",
    "    for i in range(N_attributes):\n",
    "        aux[covar_attributes[i]] = r[i]\n",
    "    records[index] = aux\n",
    "    index += 1\n",
    "    \n",
    "df = pd.read_json(json.dumps(records), orient='index')\n",
    "l = df.columns.tolist()\n",
    "d = {x:x.lower() for x in l}\n",
    "df = df.rename(columns=d)\n",
    "df = df.fillna('')\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(conn_string)\n",
    "df.to_sql('covariable', engine, if_exists='replace', index=False, chunksize=100000)\n",
    "\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    sql = \"\"\"ALTER TABLE covariable ADD COLUMN id serial\"\"\"\n",
    "    conn.execute(sql)\n",
    "    \n",
    "    for attr in covar_attributes:\n",
    "        sql = \"CREATE INDEX idx_covariable_{attr} ON covariable({attr})\".format(attr=attr)\n",
    "        conn.execute(sql)\n",
    "        \n",
    "        sql = \"CREATE INDEX idx_occurrence_{attr} ON occurrence({attr})\".format(attr=attr)\n",
    "        conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sql = \"\"\"ALTER TABLE occurrence ADD COLUMN covariable_id integer\"\"\"\n",
    "    conn.execute(sql)\n",
    "    \n",
    "    sql = \"UPDATE occurrence SET covariable_id = covariable.id FROM covariable WHERE \"\n",
    "    for attr in covar_attributes:\n",
    "        sql += \"occurrence.\" + attr + \" = \" + \"covariable.\" + attr + \" AND \"\n",
    "    sql += \"TRUE\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sql = \"CREATE INDEX idx_occurrence_id_covariable ON occurrence(covariable_id)\"\n",
    "    conn.execute(sql)\n",
    "    \n",
    "    for mesh in meshes:\n",
    "        sql = \"ALTER TABLE covariable ADD COLUMN cells_{mesh} varchar(10)[]\".format(mesh=mesh)\n",
    "        conn.execute(sql)\n",
    "        \n",
    "        sql = \"CREATE INDEX idx_covariable_cells_{mesh} ON covariable USING GIN(cells_{mesh})\".format(mesh=mesh)\n",
    "        conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "mun\n",
      "ageb\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(conn_string)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SELECT id FROM covariable ORDER BY id DESC\")\n",
    "N_covar = cur.fetchone()[0]\n",
    "\n",
    "\n",
    "for mesh in meshes:\n",
    "    print(mesh)\n",
    "    for i in range(1, N_covar+1):\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"UPDATE covariable SET cells_{mesh} = array(SELECT DISTINCT gridid_{mesh} FROM occurrence WHERE not gridid_{mesh} is null AND covariable_id =  {id_covariable})::varchar(10)[] WHERE covariable.id = {id_covariable}\". format(mesh=mesh, id_covariable=i))\n",
    "        conn.commit()\n",
    "        \n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sql =\"\"\"ALTER TABLE occurrence ADD COLUMN id serial\"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sql =\"\"\"update occurrence set gridid_ageb = 9999 where gridid_ageb is null\"\"\"\n",
    "    conn.execute(sql)\n",
    "    \n",
    "    sql =\"\"\"update occurrence set gridid_mun = 9999 where gridid_mun is null;\"\"\"\n",
    "    conn.execute(sql)\n",
    "    \n",
    "    sql =\"\"\"update occurrence set gridid_state = 9999 where gridid_state is null\"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sql =\"\"\"CREATE FUNCTION array_intersection(anyarray, anyarray)\n",
    "  RETURNS anyarray\n",
    "  language sql\n",
    "as $FUNCTION$\n",
    "    SELECT ARRAY(\n",
    "        SELECT UNNEST($1)\n",
    "        INTERSECT\n",
    "        SELECT UNNEST($2)\n",
    "    );\n",
    "$FUNCTION$;\"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
